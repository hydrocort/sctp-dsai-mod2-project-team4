{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bd4fa55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== OLIST COMBINED DATASET EXPLORATION ===\n",
      "Goal: Understand data structure, relationships, and business opportunities\n",
      "Datasets: Brazilian E-Commerce + Marketing Funnel\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Olist E-Commerce + Marketing Funnel Dataset - Initial Exploration\n",
    "# Phase 1: Data Discovery and Business Understanding\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "print(\"=== OLIST COMBINED DATASET EXPLORATION ===\")\n",
    "print(\"Goal: Understand data structure, relationships, and business opportunities\")\n",
    "print(\"Datasets: Brazilian E-Commerce + Marketing Funnel\")\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a94afea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== KAGGLE DATASET SETUP ===\n",
      "Setting up Olist E-commerce and Marketing Funnel datasets...\n",
      "------------------------------------------------------------\n",
      "âœ“ Kaggle credentials configured\n",
      "âœ“ Created directory structure: data\n",
      "âœ“ Kaggle API authenticated successfully\n",
      "\n",
      "--- Processing brazilian-ecommerce ---\n",
      "ðŸ“¥ Downloading brazilian-ecommerce dataset...\n",
      "Dataset URL: https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce\n",
      "Downloading brazilian-ecommerce.zip to data/brazilian-ecommerce\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42.6M/42.6M [00:00<00:00, 2.64GB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Downloaded and extracted brazilian-ecommerce\n",
      "âœ“ All expected files present for brazilian-ecommerce\n",
      "  - olist_customers_dataset.csv: 8.6 MB\n",
      "  - olist_orders_dataset.csv: 16.8 MB\n",
      "  - olist_order_items_dataset.csv: 14.7 MB\n",
      "  - olist_order_payments_dataset.csv: 5.5 MB\n",
      "  - olist_order_reviews_dataset.csv: 13.8 MB\n",
      "  - olist_products_dataset.csv: 2.3 MB\n",
      "  - olist_sellers_dataset.csv: 0.2 MB\n",
      "  - olist_geolocation_dataset.csv: 58.4 MB\n",
      "  - product_category_name_translation.csv: 0.0 MB\n",
      "\n",
      "--- Processing marketing-funnel ---\n",
      "ðŸ“¥ Downloading marketing-funnel dataset...\n",
      "Dataset URL: https://www.kaggle.com/datasets/olistbr/marketing-funnel-olist\n",
      "Downloading marketing-funnel-olist.zip to data/marketing-funnel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 278k/278k [00:00<00:00, 760MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Downloaded and extracted marketing-funnel\n",
      "âœ“ All expected files present for marketing-funnel\n",
      "  - olist_marketing_qualified_leads_dataset.csv: 0.7 MB\n",
      "  - olist_closed_deals_dataset.csv: 0.2 MB\n",
      "\n",
      "============================================================\n",
      "âœ… DATASET SETUP COMPLETE!\n",
      "All datasets are ready for analysis.\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# DATA SETUP: KAGGLE API DOWNLOAD AND FOLDER CREATION\n",
    "# =============================================================================\n",
    "\n",
    "def setup_kaggle_datasets():\n",
    "    \"\"\"\n",
    "    Download and setup Olist datasets from Kaggle using API\n",
    "    This function will:\n",
    "    1. Check if kaggle.json exists and set up authentication\n",
    "    2. Create necessary folder structure\n",
    "    3. Download datasets if not already present\n",
    "    4. Extract and organize files\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=== KAGGLE DATASET SETUP ===\")\n",
    "    print(\"Setting up Olist E-commerce and Marketing Funnel datasets...\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Check if kaggle.json exists\n",
    "    kaggle_json_path = Path('../kaggle.json')\n",
    "    if not kaggle_json_path.exists():\n",
    "        print(\"âŒ Error: kaggle.json file not found!\")\n",
    "        print(\"Please ensure your Kaggle API credentials are in kaggle.json\")\n",
    "        return False\n",
    "    \n",
    "    # Set up Kaggle authentication\n",
    "    kaggle_dir = Path.home() / '.kaggle'\n",
    "    kaggle_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Copy kaggle.json to ~/.kaggle/ if not already there\n",
    "    target_kaggle_json = kaggle_dir / 'kaggle.json'\n",
    "    if not target_kaggle_json.exists():\n",
    "        shutil.copy2(kaggle_json_path, target_kaggle_json)\n",
    "        # Set proper permissions (required by Kaggle API)\n",
    "        os.chmod(target_kaggle_json, 0o600)\n",
    "        print(\"âœ“ Kaggle credentials configured\")\n",
    "    \n",
    "    # Create data directory structure\n",
    "    data_dir = Path('./data')\n",
    "    ecommerce_dir = data_dir / 'brazilian-ecommerce'\n",
    "    marketing_dir = data_dir / 'marketing-funnel'\n",
    "    \n",
    "    # Create directories\n",
    "    ecommerce_dir.mkdir(parents=True, exist_ok=True)\n",
    "    marketing_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"âœ“ Created directory structure: {data_dir}\")\n",
    "    \n",
    "    # Import kaggle after setting up credentials\n",
    "    try:\n",
    "        import kaggle\n",
    "        from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "        api = KaggleApi()\n",
    "        api.authenticate()\n",
    "        print(\"âœ“ Kaggle API authenticated successfully\")\n",
    "    except ImportError:\n",
    "        print(\"âŒ Error: kaggle package not installed!\")\n",
    "        print(\"Install with: pip install kaggle\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error authenticating with Kaggle API: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # Dataset configurations\n",
    "    datasets = {\n",
    "        'brazilian-ecommerce': {\n",
    "            'dataset': 'olistbr/brazilian-ecommerce',\n",
    "            'target_dir': ecommerce_dir,\n",
    "            'expected_files': [\n",
    "                'olist_customers_dataset.csv',\n",
    "                'olist_orders_dataset.csv',\n",
    "                'olist_order_items_dataset.csv',\n",
    "                'olist_order_payments_dataset.csv',\n",
    "                'olist_order_reviews_dataset.csv',\n",
    "                'olist_products_dataset.csv',\n",
    "                'olist_sellers_dataset.csv',\n",
    "                'olist_geolocation_dataset.csv',\n",
    "                'product_category_name_translation.csv'\n",
    "            ]\n",
    "        },\n",
    "        'marketing-funnel': {\n",
    "            'dataset': 'olistbr/marketing-funnel-olist',\n",
    "            'target_dir': marketing_dir,\n",
    "            'expected_files': [\n",
    "                'olist_marketing_qualified_leads_dataset.csv',\n",
    "                'olist_closed_deals_dataset.csv'\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Download and extract datasets\n",
    "    for dataset_name, config in datasets.items():\n",
    "        print(f\"\\n--- Processing {dataset_name} ---\")\n",
    "        \n",
    "        # Check if files already exist\n",
    "        existing_files = [f for f in config['expected_files'] \n",
    "                         if (config['target_dir'] / f).exists()]\n",
    "        \n",
    "        if len(existing_files) == len(config['expected_files']):\n",
    "            print(f\"âœ“ All files already exist for {dataset_name}\")\n",
    "            # Show file sizes for verification\n",
    "            for file in config['expected_files']:\n",
    "                file_path = config['target_dir'] / file\n",
    "                size_mb = file_path.stat().st_size / (1024 * 1024)\n",
    "                print(f\"  - {file}: {size_mb:.1f} MB\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"ðŸ“¥ Downloading {dataset_name} dataset...\")\n",
    "        try:\n",
    "            # Download dataset\n",
    "            api.dataset_download_files(\n",
    "                config['dataset'], \n",
    "                path=config['target_dir'], \n",
    "                unzip=True,\n",
    "                quiet=False\n",
    "            )\n",
    "            print(f\"âœ“ Downloaded and extracted {dataset_name}\")\n",
    "            \n",
    "            # Verify files\n",
    "            missing_files = [f for f in config['expected_files'] \n",
    "                           if not (config['target_dir'] / f).exists()]\n",
    "            \n",
    "            if missing_files:\n",
    "                print(f\"âš ï¸  Warning: Some expected files are missing from {dataset_name}:\")\n",
    "                for file in missing_files:\n",
    "                    print(f\"  - {file}\")\n",
    "            else:\n",
    "                print(f\"âœ“ All expected files present for {dataset_name}\")\n",
    "                # Show file sizes\n",
    "                for file in config['expected_files']:\n",
    "                    file_path = config['target_dir'] / file\n",
    "                    if file_path.exists():\n",
    "                        size_mb = file_path.stat().st_size / (1024 * 1024)\n",
    "                        print(f\"  - {file}: {size_mb:.1f} MB\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error downloading {dataset_name}: {e}\")\n",
    "            return False\n",
    "    \n",
    "    # Clean up any zip files that might be left\n",
    "    for zip_file in data_dir.rglob(\"*.zip\"):\n",
    "        try:\n",
    "            zip_file.unlink()\n",
    "            print(f\"ðŸ—‘ï¸  Cleaned up {zip_file.name}\")\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"âœ… DATASET SETUP COMPLETE!\")\n",
    "    print(\"All datasets are ready for analysis.\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Run the setup\n",
    "setup_success = setup_kaggle_datasets()\n",
    "\n",
    "if not setup_success:\n",
    "    print(\"\\nâŒ Setup failed. Please check the error messages above.\")\n",
    "    print(\"Common solutions:\")\n",
    "    print(\"1. Ensure kaggle.json exists in the current directory\")\n",
    "    print(\"2. Install kaggle package: pip install kaggle\")\n",
    "    print(\"3. Check your internet connection\")\n",
    "    print(\"4. Verify your Kaggle API credentials are valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2912eda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1: DATA INVENTORY AND LOADING\n",
      "----------------------------------------\n",
      "Loading E-Commerce datasets...\n",
      "âœ“ customers: 99,441 rows x 5 cols\n",
      "âœ“ orders: 99,441 rows x 8 cols\n",
      "âœ“ order_items: 112,650 rows x 7 cols\n",
      "âœ“ order_payments: 103,886 rows x 5 cols\n",
      "âœ“ order_reviews: 99,224 rows x 7 cols\n",
      "âœ“ products: 32,951 rows x 9 cols\n",
      "âœ“ sellers: 3,095 rows x 4 cols\n",
      "âœ“ geolocation: 1,000,163 rows x 5 cols\n",
      "âœ“ category_translation: 71 rows x 2 cols\n",
      "\n",
      "Loading Marketing Funnel datasets...\n",
      "âœ“ marketing_qualified_leads: 8,000 rows x 4 cols\n",
      "âœ“ closed_deals: 842 rows x 14 cols\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 1: DATA INVENTORY AND LOADING\n",
    "# =============================================================================\n",
    "\n",
    "print(\"STEP 1: DATA INVENTORY AND LOADING\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Define file paths - adjust these to your local paths\n",
    "ecommerce_path = Path('./data/brazilian-ecommerce/')\n",
    "marketing_path = Path('./data/marketing-funnel/')\n",
    "\n",
    "# E-Commerce dataset files\n",
    "ecommerce_files = {\n",
    "    'customers': 'olist_customers_dataset.csv',\n",
    "    'orders': 'olist_orders_dataset.csv', \n",
    "    'order_items': 'olist_order_items_dataset.csv',\n",
    "    'order_payments': 'olist_order_payments_dataset.csv',\n",
    "    'order_reviews': 'olist_order_reviews_dataset.csv',\n",
    "    'products': 'olist_products_dataset.csv',\n",
    "    'sellers': 'olist_sellers_dataset.csv',\n",
    "    'geolocation': 'olist_geolocation_dataset.csv',\n",
    "    'category_translation': 'product_category_name_translation.csv'\n",
    "}\n",
    "\n",
    "# Marketing Funnel dataset files\n",
    "marketing_files = {\n",
    "    'marketing_qualified_leads': 'olist_marketing_qualified_leads_dataset.csv',\n",
    "    'closed_deals': 'olist_closed_deals_dataset.csv'\n",
    "}\n",
    "\n",
    "# Load all datasets\n",
    "print(\"Loading E-Commerce datasets...\")\n",
    "ecommerce_data = {}\n",
    "for name, filename in ecommerce_files.items():\n",
    "    try:\n",
    "        df = pd.read_csv(ecommerce_path / filename)\n",
    "        ecommerce_data[name] = df\n",
    "        print(f\"âœ“ {name}: {df.shape[0]:,} rows x {df.shape[1]} cols\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"âœ— {name}: File not found - {filename}\")\n",
    "\n",
    "print(\"\\nLoading Marketing Funnel datasets...\")\n",
    "marketing_data = {}\n",
    "for name, filename in marketing_files.items():\n",
    "    try:\n",
    "        df = pd.read_csv(marketing_path / filename)\n",
    "        marketing_data[name] = df\n",
    "        print(f\"âœ“ {name}: {df.shape[0]:,} rows x {df.shape[1]} cols\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"âœ— {name}: File not found - {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0cd5d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 2: INITIAL DATA PROFILING\n",
      "\n",
      "=== PROFILING ALL E-COMMERCE DATASETS ===\n",
      "\n",
      "============================================================\n",
      "\n",
      "=== E-COMMERCE: CUSTOMERS PROFILE ===\n",
      "Shape: (99441, 5)\n",
      "Memory usage: 29.62 MB\n",
      "Columns (5 total):\n",
      "  â€¢ customer_id\n",
      "  â€¢ customer_unique_id\n",
      "  â€¢ customer_zip_code_prefix\n",
      "  â€¢ customer_city\n",
      "  â€¢ customer_state\n",
      "No null values found\n",
      "Data types: {dtype('O'): 4, dtype('int64'): 1}\n",
      "\n",
      "============================================================\n",
      "\n",
      "=== E-COMMERCE: ORDERS PROFILE ===\n",
      "Shape: (99441, 8)\n",
      "Memory usage: 58.97 MB\n",
      "Columns (8 total):\n",
      "  â€¢ order_id\n",
      "  â€¢ customer_id\n",
      "  â€¢ order_status\n",
      "  â€¢ order_purchase_timestamp\n",
      "  â€¢ order_approved_at\n",
      "  â€¢ order_delivered_carrier_date\n",
      "  â€¢ order_delivered_customer_date\n",
      "  â€¢ order_estimated_delivery_date\n",
      "Null values:\n",
      "  order_approved_at: 160 (0.2%)\n",
      "  order_delivered_carrier_date: 1,783 (1.8%)\n",
      "  order_delivered_customer_date: 2,965 (3.0%)\n",
      "Data types: {dtype('O'): 8}\n",
      "\n",
      "============================================================\n",
      "\n",
      "=== E-COMMERCE: ORDER_ITEMS PROFILE ===\n",
      "Shape: (112650, 7)\n",
      "Memory usage: 39.43 MB\n",
      "Columns (7 total):\n",
      "  â€¢ order_id\n",
      "  â€¢ order_item_id\n",
      "  â€¢ product_id\n",
      "  â€¢ seller_id\n",
      "  â€¢ shipping_limit_date\n",
      "  â€¢ price\n",
      "  â€¢ freight_value\n",
      "No null values found\n",
      "Data types: {dtype('O'): 4, dtype('float64'): 2, dtype('int64'): 1}\n",
      "\n",
      "============================================================\n",
      "\n",
      "=== E-COMMERCE: ORDER_PAYMENTS PROFILE ===\n",
      "Shape: (103886, 5)\n",
      "Memory usage: 17.81 MB\n",
      "Columns (5 total):\n",
      "  â€¢ order_id\n",
      "  â€¢ payment_sequential\n",
      "  â€¢ payment_type\n",
      "  â€¢ payment_installments\n",
      "  â€¢ payment_value\n",
      "No null values found\n",
      "Data types: {dtype('O'): 2, dtype('int64'): 2, dtype('float64'): 1}\n",
      "\n",
      "============================================================\n",
      "\n",
      "=== E-COMMERCE: ORDER_REVIEWS PROFILE ===\n",
      "Shape: (99224, 7)\n",
      "Memory usage: 42.75 MB\n",
      "Columns (7 total):\n",
      "  â€¢ review_id\n",
      "  â€¢ order_id\n",
      "  â€¢ review_score\n",
      "  â€¢ review_comment_title\n",
      "  â€¢ review_comment_message\n",
      "  â€¢ review_creation_date\n",
      "  â€¢ review_answer_timestamp\n",
      "Null values:\n",
      "  review_comment_title: 87,656 (88.3%)\n",
      "  review_comment_message: 58,247 (58.7%)\n",
      "Data types: {dtype('O'): 6, dtype('int64'): 1}\n",
      "\n",
      "============================================================\n",
      "\n",
      "=== E-COMMERCE: PRODUCTS PROFILE ===\n",
      "Shape: (32951, 9)\n",
      "Memory usage: 6.79 MB\n",
      "Columns (9 total):\n",
      "  â€¢ product_id\n",
      "  â€¢ product_category_name\n",
      "  â€¢ product_name_lenght\n",
      "  â€¢ product_description_lenght\n",
      "  â€¢ product_photos_qty\n",
      "  â€¢ product_weight_g\n",
      "  â€¢ product_length_cm\n",
      "  â€¢ product_height_cm\n",
      "  â€¢ product_width_cm\n",
      "Null values:\n",
      "  product_category_name: 610 (1.9%)\n",
      "  product_name_lenght: 610 (1.9%)\n",
      "  product_description_lenght: 610 (1.9%)\n",
      "  product_photos_qty: 610 (1.9%)\n",
      "  product_weight_g: 2 (0.0%)\n",
      "  product_length_cm: 2 (0.0%)\n",
      "  product_height_cm: 2 (0.0%)\n",
      "  product_width_cm: 2 (0.0%)\n",
      "Data types: {dtype('float64'): 7, dtype('O'): 2}\n",
      "\n",
      "============================================================\n",
      "\n",
      "=== E-COMMERCE: SELLERS PROFILE ===\n",
      "Shape: (3095, 4)\n",
      "Memory usage: 0.66 MB\n",
      "Columns (4 total):\n",
      "  â€¢ seller_id\n",
      "  â€¢ seller_zip_code_prefix\n",
      "  â€¢ seller_city\n",
      "  â€¢ seller_state\n",
      "No null values found\n",
      "Data types: {dtype('O'): 3, dtype('int64'): 1}\n",
      "\n",
      "============================================================\n",
      "\n",
      "=== E-COMMERCE: GEOLOCATION PROFILE ===\n",
      "Shape: (1000163, 5)\n",
      "Memory usage: 145.20 MB\n",
      "Columns (5 total):\n",
      "  â€¢ geolocation_zip_code_prefix\n",
      "  â€¢ geolocation_lat\n",
      "  â€¢ geolocation_lng\n",
      "  â€¢ geolocation_city\n",
      "  â€¢ geolocation_state\n",
      "No null values found\n",
      "Data types: {dtype('float64'): 2, dtype('O'): 2, dtype('int64'): 1}\n",
      "\n",
      "============================================================\n",
      "\n",
      "=== E-COMMERCE: CATEGORY_TRANSLATION PROFILE ===\n",
      "Shape: (71, 2)\n",
      "Memory usage: 0.01 MB\n",
      "Columns (2 total):\n",
      "  â€¢ product_category_name\n",
      "  â€¢ product_category_name_english\n",
      "No null values found\n",
      "Data types: {dtype('O'): 2}\n",
      "\n",
      "\n",
      "=== PROFILING ALL MARKETING DATASETS ===\n",
      "\n",
      "============================================================\n",
      "\n",
      "=== MARKETING: MARKETING_QUALIFIED_LEADS PROFILE ===\n",
      "Shape: (8000, 4)\n",
      "Memory usage: 2.38 MB\n",
      "Columns (4 total):\n",
      "  â€¢ mql_id\n",
      "  â€¢ first_contact_date\n",
      "  â€¢ landing_page_id\n",
      "  â€¢ origin\n",
      "Null values:\n",
      "  origin: 60 (0.8%)\n",
      "Data types: {dtype('O'): 4}\n",
      "\n",
      "============================================================\n",
      "\n",
      "=== MARKETING: CLOSED_DEALS PROFILE ===\n",
      "Shape: (842, 14)\n",
      "Memory usage: 0.65 MB\n",
      "Columns (14 total):\n",
      "  â€¢ mql_id\n",
      "  â€¢ seller_id\n",
      "  â€¢ sdr_id\n",
      "  â€¢ sr_id\n",
      "  â€¢ won_date\n",
      "  â€¢ business_segment\n",
      "  â€¢ lead_type\n",
      "  â€¢ lead_behaviour_profile\n",
      "  â€¢ has_company\n",
      "  â€¢ has_gtin\n",
      "  â€¢ average_stock\n",
      "  â€¢ business_type\n",
      "  â€¢ declared_product_catalog_size\n",
      "  â€¢ declared_monthly_revenue\n",
      "Null values:\n",
      "  business_segment: 1 (0.1%)\n",
      "  lead_type: 6 (0.7%)\n",
      "  lead_behaviour_profile: 177 (21.0%)\n",
      "  has_company: 779 (92.5%)\n",
      "  has_gtin: 778 (92.4%)\n",
      "  average_stock: 776 (92.2%)\n",
      "  business_type: 10 (1.2%)\n",
      "  declared_product_catalog_size: 773 (91.8%)\n",
      "Data types: {dtype('O'): 12, dtype('float64'): 2}\n",
      "\n",
      "============================================================\n",
      "SUMMARY: Profiled 9 e-commerce datasets and 2 marketing datasets\n",
      "E-commerce datasets: ['customers', 'orders', 'order_items', 'order_payments', 'order_reviews', 'products', 'sellers', 'geolocation', 'category_translation']\n",
      "Marketing datasets: ['marketing_qualified_leads', 'closed_deals']\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 2: INITIAL DATA PROFILING\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 2: INITIAL DATA PROFILING\")\n",
    "\n",
    "def profile_dataset(df, name):\n",
    "    \"\"\"Quick data profiling function\"\"\"\n",
    "    print(f\"\\n=== {name.upper()} PROFILE ===\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    \n",
    "    # Display columns as bulleted list\n",
    "    print(f\"Columns ({len(df.columns)} total):\")\n",
    "    for col in df.columns:\n",
    "        print(f\"  â€¢ {col}\")\n",
    "    \n",
    "    # Null values\n",
    "    null_counts = df.isnull().sum()\n",
    "    if null_counts.sum() > 0:\n",
    "        print(f\"Null values:\")\n",
    "        for col, count in null_counts[null_counts > 0].items():\n",
    "            print(f\"  {col}: {count:,} ({count/len(df)*100:.1f}%)\")\n",
    "    else:\n",
    "        print(\"No null values found\")\n",
    "    \n",
    "    # Data types\n",
    "    print(f\"Data types: {df.dtypes.value_counts().to_dict()}\")\n",
    "    \n",
    "    return df.describe(include='all')\n",
    "\n",
    "# Profile ALL datasets from both e-commerce and marketing collections\n",
    "print(\"\\n=== PROFILING ALL E-COMMERCE DATASETS ===\")\n",
    "ecommerce_profiles = {}\n",
    "for dataset_name, dataset_df in ecommerce_data.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    ecommerce_profiles[dataset_name] = profile_dataset(dataset_df, f\"E-Commerce: {dataset_name}\")\n",
    "\n",
    "print(\"\\n\\n=== PROFILING ALL MARKETING DATASETS ===\")\n",
    "marketing_profiles = {}\n",
    "for dataset_name, dataset_df in marketing_data.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    marketing_profiles[dataset_name] = profile_dataset(dataset_df, f\"Marketing: {dataset_name}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"SUMMARY: Profiled {len(ecommerce_profiles)} e-commerce datasets and {len(marketing_profiles)} marketing datasets\")\n",
    "print(f\"E-commerce datasets: {list(ecommerce_profiles.keys())}\")\n",
    "print(f\"Marketing datasets: {list(marketing_profiles.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25b15a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 3: MARKETING FUNNEL CONNECTION ANALYSIS\n",
      "----------------------------------------\n",
      "Marketing Funnel Structure:\n",
      "1. Marketing Qualified Leads: 8,000 leads\n",
      "2. Closed Deals: 842 deals\n",
      "3. MQL to Deal Conversion: 842 converted (10.5%)\n",
      "4. Sellers from Marketing: 842 out of 3,095 total sellers\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 3: UNDERSTANDING THE MARKETING FUNNEL CONNECTION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 3: MARKETING FUNNEL CONNECTION ANALYSIS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Based on the Kaggle joining instructions, the connection is:\n",
    "# Marketing Qualified Leads -> Closed Deals -> Sellers -> Orders\n",
    "\n",
    "if 'marketing_qualified_leads' in marketing_data and 'closed_deals' in marketing_data:\n",
    "    mql_df = marketing_data['marketing_qualified_leads']\n",
    "    deals_df = marketing_data['closed_deals']\n",
    "    \n",
    "    print(\"Marketing Funnel Structure:\")\n",
    "    print(f\"1. Marketing Qualified Leads: {mql_df.shape[0]:,} leads\")\n",
    "    print(f\"2. Closed Deals: {deals_df.shape[0]:,} deals\")\n",
    "    \n",
    "    # Check the connection between MQL and Deals\n",
    "    if 'mql_id' in mql_df.columns and 'mql_id' in deals_df.columns:\n",
    "        mql_to_deals = deals_df['mql_id'].nunique()\n",
    "        conversion_rate = mql_to_deals / mql_df.shape[0] * 100\n",
    "        print(f\"3. MQL to Deal Conversion: {mql_to_deals:,} converted ({conversion_rate:.1f}%)\")\n",
    "    \n",
    "    # Check seller connection\n",
    "    if 'seller_id' in deals_df.columns and 'sellers' in ecommerce_data:\n",
    "        sellers_df = ecommerce_data['sellers']\n",
    "        marketing_sellers = deals_df['seller_id'].nunique()\n",
    "        total_sellers = sellers_df['seller_id'].nunique()\n",
    "        print(f\"4. Sellers from Marketing: {marketing_sellers:,} out of {total_sellers:,} total sellers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b720afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 4: JOIN THE DATASETS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 4: JOINING E-COMMERCE AND MARKETING DATA\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Following the Kaggle joining instructions:\n",
    "# MQL -> Closed Deals -> Sellers -> Order Items -> Orders\n",
    "\n",
    "if all(key in marketing_data for key in ['marketing_qualified_leads', 'closed_deals']) and \\\n",
    "   all(key in ecommerce_data for key in ['sellers', 'order_items', 'orders']):\n",
    "    \n",
    "    print(\"Creating comprehensive joined dataset...\")\n",
    "    \n",
    "    # Step 1: Join MQL with Closed Deals\n",
    "    mql_deals = pd.merge(\n",
    "        marketing_data['marketing_qualified_leads'],\n",
    "        marketing_data['closed_deals'],\n",
    "        on='mql_id',\n",
    "        how='inner'\n",
    "    )\n",
    "    print(f\"MQL + Deals: {mql_deals.shape[0]:,} records\")\n",
    "    \n",
    "    # Step 2: Join with Sellers\n",
    "    deals_sellers = pd.merge(\n",
    "        mql_deals,\n",
    "        ecommerce_data['sellers'],\n",
    "        on='seller_id',\n",
    "        how='inner'\n",
    "    )\n",
    "    print(f\"+ Sellers: {deals_sellers.shape[0]:,} records\")\n",
    "    \n",
    "    # Step 3: Join with Order Items\n",
    "    deals_order_items = pd.merge(\n",
    "        deals_sellers,\n",
    "        ecommerce_data['order_items'],\n",
    "        on='seller_id',\n",
    "        how='inner'\n",
    "    )\n",
    "    print(f\"+ Order Items: {deals_order_items.shape[0]:,} records\")\n",
    "    \n",
    "    # Step 4: Join with Orders\n",
    "    combined_dataset = pd.merge(\n",
    "        deals_order_items,\n",
    "        ecommerce_data['orders'],\n",
    "        on='order_id',\n",
    "        how='inner'\n",
    "    )\n",
    "    print(f\"+ Orders: {combined_dataset.shape[0]:,} records\")\n",
    "    \n",
    "    # Step 5: Add customer information\n",
    "    if 'customers' in ecommerce_data:\n",
    "        combined_dataset = pd.merge(\n",
    "            combined_dataset,\n",
    "            ecommerce_data['customers'],\n",
    "            on='customer_id',\n",
    "            how='left'\n",
    "        )\n",
    "        print(f\"+ Customers: {combined_dataset.shape[0]:,} records\")\n",
    "    \n",
    "    # Step 6: Add product information\n",
    "    if 'products' in ecommerce_data:\n",
    "        combined_dataset = pd.merge(\n",
    "            combined_dataset,\n",
    "            ecommerce_data['products'],\n",
    "            on='product_id',\n",
    "            how='left'\n",
    "        )\n",
    "        print(f\"+ Products: {combined_dataset.shape[0]:,} records\")\n",
    "    \n",
    "    print(f\"\\nFinal combined dataset shape: {combined_dataset.shape}\")\n",
    "    print(f\"Columns: {combined_dataset.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f75f41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 5: BUSINESS QUESTIONS DISCOVERY\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 5: BUSINESS QUESTIONS DISCOVERY\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "if 'combined_dataset' in locals():\n",
    "    print(\"Analyzing business opportunities with combined dataset...\\n\")\n",
    "    \n",
    "    # Marketing Attribution Analysis\n",
    "    print(\"1. MARKETING ATTRIBUTION OPPORTUNITIES:\")\n",
    "    \n",
    "    # Lead source effectiveness\n",
    "    if 'lead_type' in combined_dataset.columns:\n",
    "        lead_performance = combined_dataset.groupby('lead_type').agg({\n",
    "            'price': ['count', 'sum', 'mean'],\n",
    "            'order_id': 'nunique'\n",
    "        }).round(2)\n",
    "        print(\"Lead Type Performance:\")\n",
    "        print(lead_performance.head())\n",
    "    \n",
    "    # Marketing channel ROI\n",
    "    if 'origin' in combined_dataset.columns:\n",
    "        channel_performance = combined_dataset.groupby('origin').agg({\n",
    "            'price': ['count', 'sum'],\n",
    "            'freight_value': 'sum'\n",
    "        }).round(2)\n",
    "        print(\"\\nMarketing Channel Performance:\")\n",
    "        print(channel_performance.head())\n",
    "    \n",
    "    # 2. Customer Lifecycle Analysis\n",
    "    print(\"\\n2. CUSTOMER LIFECYCLE OPPORTUNITIES:\")\n",
    "    \n",
    "    # Time from lead to purchase\n",
    "    if 'first_contact_date' in combined_dataset.columns and 'order_purchase_timestamp' in combined_dataset.columns:\n",
    "        combined_dataset['first_contact_date'] = pd.to_datetime(combined_dataset['first_contact_date'])\n",
    "        combined_dataset['order_purchase_timestamp'] = pd.to_datetime(combined_dataset['order_purchase_timestamp'])\n",
    "        combined_dataset['lead_to_purchase_days'] = (\n",
    "            combined_dataset['order_purchase_timestamp'] - combined_dataset['first_contact_date']\n",
    "        ).dt.days\n",
    "        \n",
    "        print(f\"Lead to Purchase Time (days):\")\n",
    "        print(combined_dataset['lead_to_purchase_days'].describe())\n",
    "    \n",
    "    # 3. Geographic Analysis\n",
    "    print(\"\\n3. GEOGRAPHIC OPPORTUNITIES:\")\n",
    "    \n",
    "    if 'seller_state' in combined_dataset.columns and 'customer_state' in combined_dataset.columns:\n",
    "        # Cross-state sales from marketing\n",
    "        geo_analysis = combined_dataset.groupby(['seller_state', 'customer_state']).agg({\n",
    "            'price': 'sum',\n",
    "            'order_id': 'nunique'\n",
    "        }).reset_index()\n",
    "        \n",
    "        print(\"Top 10 Seller-Customer State Combinations:\")\n",
    "        top_geo = geo_analysis.nlargest(10, 'price')\n",
    "        print(top_geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22730e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 6: COMPREHENSIVE BUSINESS QUESTIONS LIST\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 6: COMPREHENSIVE BUSINESS QUESTIONS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "business_questions = [\n",
    "    # Marketing Attribution\n",
    "    \"1. Which marketing channels (lead sources) generate the highest revenue?\",\n",
    "    \"2. What is the ROI of different marketing campaigns?\",\n",
    "    \"3. How long does it take from first contact to purchase?\",\n",
    "    \"4. Which lead types convert to the highest-value customers?\",\n",
    "    \n",
    "    # Customer Lifecycle\n",
    "    \"5. What is the customer acquisition cost by channel?\",\n",
    "    \"6. How does marketing-acquired customer behavior differ from organic customers?\",\n",
    "    \"7. What is the lifetime value of marketing-acquired customers?\",\n",
    "    \"8. Which marketing touchpoints lead to repeat purchases?\",\n",
    "    \n",
    "    # Seller Performance\n",
    "    \"9. How do marketing-acquired sellers perform vs. organic sellers?\",\n",
    "    \"10. Which seller onboarding channels lead to better long-term performance?\",\n",
    "    \"11. What is the seller retention rate by acquisition channel?\",\n",
    "    \n",
    "    # Product & Category Analysis\n",
    "    \"12. Which product categories benefit most from marketing investment?\",\n",
    "    \"13. How does marketing affect seasonal product sales?\",\n",
    "    \"14. What products do marketing-acquired customers prefer?\",\n",
    "    \n",
    "    # Geographic Insights\n",
    "    \"15. How does marketing effectiveness vary by Brazilian state?\",\n",
    "    \"16. Which regions have untapped marketing potential?\",\n",
    "    \"17. How does shipping cost affect marketing ROI by location?\",\n",
    "    \n",
    "    # Business Intelligence\n",
    "    \"18. What are the key metrics for marketing campaign optimization?\",\n",
    "    \"19. How can we predict which leads will convert to high-value customers?\",\n",
    "    \"20. What marketing mix generates the best overall marketplace health?\"\n",
    "]\n",
    "\n",
    "print(\"COMPREHENSIVE BUSINESS QUESTIONS WITH COMBINED DATASET:\")\n",
    "for question in business_questions:\n",
    "    print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cff3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 7: PROPOSED STAR SCHEMA DESIGN\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 7: PROPOSED STAR SCHEMA DESIGN\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "print(\"\"\"\n",
    "ENHANCED STAR SCHEMA WITH MARKETING FUNNEL DATA:\n",
    "\n",
    "FACT TABLE: FactSales\n",
    "- Grain: One row per order item (enhanced with marketing attribution)\n",
    "- Estimated rows: ~117,000+ (from order_items + marketing attribution)\n",
    "\n",
    "CORE MEASURES:\n",
    "- price (unit price)\n",
    "- freight_value \n",
    "- total_value (price + freight)\n",
    "- lead_to_purchase_days (new!)\n",
    "- marketing_cost_allocation (new!)\n",
    "\n",
    "DIMENSION TABLES:\n",
    "\n",
    "1. DimCustomer\n",
    "   - customer_id, customer_unique_id\n",
    "   - customer_city, customer_state, customer_zip_code_prefix\n",
    "   - acquisition_channel (organic vs marketing)\n",
    "\n",
    "2. DimProduct  \n",
    "   - product_id, product_category_name\n",
    "   - product_name_length, product_description_length\n",
    "   - product_photos_qty, product_weight_g, product_length_cm, etc.\n",
    "\n",
    "3. DimSeller (ENHANCED)\n",
    "   - seller_id, seller_zip_code_prefix, seller_city, seller_state\n",
    "   - acquisition_channel (organic vs marketing)\n",
    "   - mql_id, deal_close_date (new marketing fields!)\n",
    "\n",
    "4. DimDate\n",
    "   - Date hierarchy for orders and marketing events\n",
    "   - order_date, estimated_delivery_date, delivered_date\n",
    "   - first_contact_date, deal_close_date (new!)\n",
    "\n",
    "5. DimGeography\n",
    "   - Geographic lookup for Brazilian states/cities\n",
    "   - Both seller and customer geography\n",
    "\n",
    "6. DimPayment\n",
    "   - payment_type, payment_installments\n",
    "   - payment_value\n",
    "\n",
    "7. DimMarketing (NEW!)\n",
    "   - mql_id, lead_type, lead_behaviour_profile\n",
    "   - origin (marketing channel)\n",
    "   - first_contact_date, landing_page_id\n",
    "   - business_segment, business_type\n",
    "\n",
    "8. DimProduct Category (NEW!)\n",
    "   - product_category_name (Portuguese)\n",
    "   - product_category_name_english\n",
    "   - category_group (custom groupings)\n",
    "\n",
    "BRIDGE TABLE (Optional):\n",
    "- BridgeMarketingAttribution\n",
    "   - Links orders to multiple marketing touchpoints\n",
    "   - Handles multi-touch attribution\n",
    "\n",
    "KEY RELATIONSHIPS:\n",
    "FactSales connects to:\n",
    "- DimCustomer via customer_key\n",
    "- DimProduct via product_key  \n",
    "- DimSeller via seller_key\n",
    "- DimDate via order_date_key\n",
    "- DimMarketing via mql_key (for marketing-attributed sales)\n",
    "- DimPayment via payment_key\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a149ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 8: DATA QUALITY ASSESSMENT\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 8: DATA QUALITY ASSESSMENT\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "if 'combined_dataset' in locals():\n",
    "    print(\"Data Quality Issues Identified:\")\n",
    "    \n",
    "    # Check for missing values in key fields\n",
    "    key_fields = ['order_id', 'customer_id', 'seller_id', 'product_id', 'price']\n",
    "    missing_analysis = {}\n",
    "    \n",
    "    for field in key_fields:\n",
    "        if field in combined_dataset.columns:\n",
    "            missing_count = combined_dataset[field].isnull().sum()\n",
    "            missing_pct = missing_count / len(combined_dataset) * 100\n",
    "            missing_analysis[field] = {'count': missing_count, 'percentage': missing_pct}\n",
    "            \n",
    "            if missing_count > 0:\n",
    "                print(f\"âš ï¸  {field}: {missing_count:,} missing ({missing_pct:.1f}%)\")\n",
    "            else:\n",
    "                print(f\"âœ“ {field}: No missing values\")\n",
    "    \n",
    "    # Check for duplicates\n",
    "    if len(combined_dataset) > 0:\n",
    "        duplicates = combined_dataset.duplicated().sum()\n",
    "        print(f\"\\nDuplicate rows: {duplicates:,}\")\n",
    "        \n",
    "        # Check business key uniqueness\n",
    "        if 'order_id' in combined_dataset.columns and 'order_item_id' in combined_dataset.columns:\n",
    "            business_key_dupes = combined_dataset.duplicated(['order_id', 'order_item_id']).sum()\n",
    "            print(f\"Business key duplicates (order_id + order_item_id): {business_key_dupes:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5895de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 9: IMPLEMENTATION RECOMMENDATIONS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 9: IMPLEMENTATION RECOMMENDATIONS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "print(\"\"\"\n",
    "PHASE 2 IMPLEMENTATION PLAN:\n",
    "\n",
    "1. DATA PIPELINE SETUP:\n",
    "   - Use Meltano to ingest both CSV datasets\n",
    "   - Create staging tables in BigQuery\n",
    "   - Implement incremental loading for ongoing data\n",
    "\n",
    "2. DBT TRANSFORMATIONS:\n",
    "   - Create staging models for each source table\n",
    "   - Build dimension tables with proper SCD Type 2 for sellers\n",
    "   - Create fact table with marketing attribution\n",
    "   - Add data quality tests at each layer\n",
    "\n",
    "3. GREAT EXPECTATIONS RULES:\n",
    "   - Order values must be positive\n",
    "   - All order_items must have valid order_id references\n",
    "   - Marketing leads must have valid conversion dates\n",
    "   - Geographic codes must match Brazilian standards\n",
    "   - Lead-to-purchase time must be reasonable (0-365 days)\n",
    "\n",
    "4. BUSINESS INTELLIGENCE LAYER:\n",
    "   - Marketing attribution dashboard\n",
    "   - Customer acquisition cost analysis\n",
    "   - Seller performance by acquisition channel\n",
    "   - Geographic market penetration analysis\n",
    "\n",
    "5. ADVANCED ANALYTICS:\n",
    "   - Lead scoring model\n",
    "   - Customer lifetime value prediction\n",
    "   - Marketing mix optimization\n",
    "   - Churn prediction for marketing-acquired customers\n",
    "\n",
    "EXPECTED DELIVERABLES:\n",
    "- Star schema with marketing attribution\n",
    "- Marketing ROI dashboard\n",
    "- Customer acquisition cost analysis\n",
    "- Seller onboarding effectiveness report\n",
    "- Geographic expansion opportunity analysis\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PHASE 1 EDA COMPLETE!\")\n",
    "print(\"Next Steps: Proceed to infrastructure setup and implementation\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mod2proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
